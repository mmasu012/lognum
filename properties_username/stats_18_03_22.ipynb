{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "23e6d03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from os.path import exists\n",
    "import re\n",
    "import wordsegment as ws\n",
    "from wordsegment import load, segment, clean\n",
    "load()\n",
    "import enchant\n",
    "english_dict = enchant.Dict(\"en_US\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fb8d215a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BIGRAMS',\n",
       " 'Segmenter',\n",
       " 'UNIGRAMS',\n",
       " 'WORDS',\n",
       " '__all__',\n",
       " '__author__',\n",
       " '__build__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__copyright__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__license__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '__title__',\n",
       " '__version__',\n",
       " '_segmenter',\n",
       " 'clean',\n",
       " 'io',\n",
       " 'isegment',\n",
       " 'load',\n",
       " 'main',\n",
       " 'math',\n",
       " 'op',\n",
       " 'segment',\n",
       " 'sys']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# divide('v.i.r.u.s')\n",
    "# clean('v.i.r.u.s')\n",
    "dir(ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d8a9222",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ethical_hacker']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forum_list = [\n",
    "        \n",
    "        'ethical_hacker',\n",
    "        # 'hack_this_site',\n",
    "        # 'mpgh',\n",
    "        # 'security_stack_exchange',\n",
    "        # 'garage4hackers',\n",
    "        # 'wilderssecurity',\n",
    "        # 'offensive_community',\n",
    "        # 'hack_forums',\n",
    "        # 'raidforums',\n",
    "        # 'google_plus',\n",
    "        # 'facebook',\n",
    "        # 'twitter',         \n",
    "]\n",
    "forum_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36ef2b45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ethical_hacker'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forum_name = forum_list[0]\n",
    "forum_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7cb7fbe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'processed/ethical_hacker_usernames.csv'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = 'processed/'\n",
    "file_location = data_dir + forum_name + '_usernames.csv'\n",
    "file_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eaec71be",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(file_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eea60897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'name'], dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "acd2958d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [index, name]\n",
       "Index: []"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5cbe4ed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index    0\n",
       "name     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77f5f90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "slangification_map={\n",
    "    '0': ['o'],\n",
    "    '1': ['i', 'l', 't'],\n",
    "    '2': ['z'],\n",
    "    '3': ['e', 's'],\n",
    "    '4': ['a', 'r'],\n",
    "    '5': ['s'],\n",
    "    '6': ['g'],\n",
    "    '7': ['t'],\n",
    "    '8': ['b'],\n",
    "    '9': ['g'],\n",
    "    '@': ['a'],\n",
    "    '!': ['i'],\n",
    "    '$': ['s'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fb65e285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2', '3', '4', '1', '1', '2', '$']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall('[' + ''.join(slangification_map.keys()) + ']{1,1}', '[23ma[4s1ud12$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6811600b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "['m.lasudlover', 'm.iasudlover', 'm.tasudlovsr', 'm.lasudlovsr', 'm.tasudlover', 'm.iasudlovsr']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Considering all slangifying chars will be slangified all at once, if found\n",
    "def slangify(username):\n",
    "    \n",
    "    slang_chars = re.findall('[' + ''.join(slangification_map.keys()) + ']{1,1}', username)\n",
    "    # print(slang_chars)\n",
    "    \n",
    "    \n",
    "    if len(slang_chars) > 0:\n",
    "        \n",
    "        transformed_usernames=[username]\n",
    "        for char in slang_chars:\n",
    "            \n",
    "            replace_vals = slangification_map[char]\n",
    "            temp = []\n",
    "            \n",
    "            for r_v in replace_vals:\n",
    "                for t_u in transformed_usernames:\n",
    "                    temp.append( t_u.replace(char, r_v) )\n",
    "            \n",
    "            transformed_usernames = temp\n",
    "        \n",
    "        \n",
    "        transformed_usernames = list(set(transformed_usernames))\n",
    "        # print('Transformation is finished', transformed_usernames)\n",
    "        \n",
    "        return transformed_usernames\n",
    "    \n",
    "    else:\n",
    "        return []\n",
    "    \n",
    "print('test')\n",
    "print(slangify('m.1@$udlov3r'))\n",
    "print(slangify('masud'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "87517f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract meaningful words\n",
    "def extract_meaningful_chunks(username):\n",
    "    \n",
    "    chunks_based_on_word_segmentation = segment(username)\n",
    "#     print(username, len(username))\n",
    "#     print(chunks_based_on_word_segmentation)\n",
    "    \n",
    "    meaningful_chunks = []\n",
    "    sentiment_score = 0\n",
    "    length = 0\n",
    "    for chunk in chunks_based_on_word_segmentation:\n",
    "        \n",
    "        \n",
    "        \n",
    "        if len(chunk) >= 1:\n",
    "            \n",
    "            # check in two dataset\n",
    "            if english_dict.check(chunk):\n",
    "                meaningful_chunks.append(chunk)\n",
    "                length += len(chunk)\n",
    "\n",
    "#     print(length)   \n",
    "    \n",
    "\n",
    "#         synsets = wordnet.synsets(chunk)\n",
    "#         if synsets:\n",
    "#             synset = synsets[0]\n",
    "#             meaningful_chunks.append(chunk)\n",
    "#             sentiment_score += cal_sentiment_score(synset.name())\n",
    "#             # print(chunk, synset.lexname(), sentiment_score)\n",
    "            \n",
    "#     meaningful_chunks = set(meaningful_chunks)\n",
    "#     print('Meaningful chunks', list(meaningful_chunks))\n",
    "    \n",
    "    return length, meaningful_chunks, chunks_based_on_word_segmentation\n",
    "    \n",
    "#     meaningless_chunks = \\\n",
    "#         set(chunks_based_on_word_segmentation) - set(meaningful_chunks)\n",
    "        \n",
    "#     # print('Meaningless chunks', list(meaningless_chunks))\n",
    "    \n",
    "#     return list(meaningful_chunks), list(meaningless_chunks), sentiment_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "22976403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toym.iasudlov.erlov.er ['toy', 'lover', 'lover'] ['toy', 'mia', 'sud', 'lover', 'lover']\n"
     ]
    }
   ],
   "source": [
    "root = '7oym.1@$udlov.3rlov.3r'\n",
    "chunks = slangify('7oym.1@$udlov.3rlov.3r')\n",
    "# chunks = slangify('masudh@ppy')\n",
    "\n",
    "max_length = 0\n",
    "max_meaningful_chunkification = []\n",
    "max_slangification = ''\n",
    "max_chunks_based_on_word_segmentation = []\n",
    "for chunk in chunks:\n",
    "    \n",
    "    length, meaningful_chunks, chunks_based_on_word_segmentation = extract_meaningful_chunks(chunk)\n",
    "    if length > max_length:\n",
    "        max_length = length\n",
    "        max_meaningful_chunkification = meaningful_chunks\n",
    "        max_slangification = chunk\n",
    "        max_chunks_based_on_word_segmentation = chunks_based_on_word_segmentation\n",
    "print(max_slangification, max_meaningful_chunkification, max_chunks_based_on_word_segmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "1dfaec38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterative Python program to check if a\n",
    "# string is subsequence of another string\n",
    " \n",
    "# Returns true if str1 is a subsequence of str2\n",
    " \n",
    "# str1 = \"lover\"\n",
    "# str2 = \"lovetoym.iasudlov.erlov.er\"\n",
    "def isSubSequence(str1, str2, start_pos_str2):\n",
    "    m = len(str1)\n",
    "    n = len(str2)\n",
    " \n",
    "    j = 0    # Index of str1\n",
    "#     i = 0    # Index of str2\n",
    "    i = start_pos_str2\n",
    " \n",
    "    # Traverse both str1 and str2\n",
    "    # Compare current character of str2 with\n",
    "    # first unmatched character of str1\n",
    "    # If matched, then move ahead in str1\n",
    " \n",
    "    while j < m and i < n:\n",
    "        if str1[j] == str2[i]:\n",
    "            j = j+1\n",
    "        i = i + 1\n",
    " \n",
    "    # If all characters of str1 matched,\n",
    "    # then j is equal to m\n",
    "    \n",
    "#     if j == m:\n",
    "        \n",
    "    end = i\n",
    "    i = i - 1\n",
    "    j = m - 1\n",
    "\n",
    "    while j > -1 and i > start_pos_str2 - 1:\n",
    "        if str1[j] == str2[i]:\n",
    "            j = j-1\n",
    "        i = i - 1\n",
    "    i += 2\n",
    "    start = i\n",
    "\n",
    "    return start, end\n",
    "    \n",
    "#     else:\n",
    "#         return -1, -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "2a366735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 3\n",
      "11 16\n",
      "11 16\n"
     ]
    }
   ],
   "source": [
    "mapper = {}\n",
    "if len(max_meaningful_chunkification) > 0:\n",
    "    \n",
    "    index = 0\n",
    "    for meaningful_chunkification in max_meaningful_chunkification:\n",
    "        start, end = isSubSequence(meaningful_chunkification, max_slangification, index)\n",
    "        index = end\n",
    "#         print(meaningful_chunkification, max_slangification)\n",
    "        print(start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "5c0c49e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "( 15 , 20 )\n",
      "1 l\n",
      "2 o\n",
      "3 v\n",
      "4 e\n",
      "5 t\n",
      "6 o\n",
      "7 y\n",
      "8 m\n",
      "9 .\n",
      "10 i\n",
      "11 a\n",
      "12 s\n",
      "13 u\n",
      "14 d\n",
      "15 l\n",
      "16 o\n",
      "17 v\n",
      "18 .\n",
      "19 e\n",
      "20 r\n",
      "21 l\n",
      "22 o\n",
      "23 v\n",
      "24 .\n",
      "25 e\n",
      "26 r\n"
     ]
    }
   ],
   "source": [
    "# Iterative Python program to check if a\n",
    "# string is subsequence of another string\n",
    " \n",
    "# Returns true if str1 is a subsequence of str2\n",
    " \n",
    "# str1 = \"lover\"\n",
    "# str2 = \"lovetoym.iasudlov.erlov.er\"\n",
    "def isSubSequence(str1, str2):\n",
    "    m = len(str1)\n",
    "    n = len(str2)\n",
    " \n",
    "    j = 0    # Index of str1\n",
    "    i = 0    # Index of str2\n",
    " \n",
    "    # Traverse both str1 and str2\n",
    "    # Compare current character of str2 with\n",
    "    # first unmatched character of str1\n",
    "    # If matched, then move ahead in str1\n",
    " \n",
    "    while j < m and i < n:\n",
    "        if str1[j] == str2[i]:\n",
    "            j = j+1\n",
    "        i = i + 1\n",
    " \n",
    "    # If all characters of str1 matched,\n",
    "    # then j is equal to m\n",
    "    \n",
    "    if j == m:\n",
    "        \n",
    "        end = i\n",
    "        i = i - 1\n",
    "        j = m - 1\n",
    "    \n",
    "        while j > -1 and i > -1:\n",
    "            if str1[j] == str2[i]:\n",
    "                j = j-1\n",
    "            i = i - 1\n",
    "        i += 2\n",
    "        start = i\n",
    "        \n",
    "        return start, end\n",
    "    \n",
    "    else:\n",
    "        return -1, -1\n",
    "    \n",
    " \n",
    "# Driver Program\n",
    " \n",
    " \n",
    "# str1 = \"gksrek\"\n",
    "# str2 = \"geeksforgeeks\"\n",
    "str1 = \"lover\"\n",
    "str2 = \"lovetoym.iasudlov.erlov.er\"\n",
    "\n",
    "start, end = isSubSequence(str1, str2)\n",
    "if start > 0 and end > 0:\n",
    "    \n",
    "    print ('(', start, ',', end, ')')\n",
    "else:\n",
    "    print('not found')\n",
    " \n",
    "# Contributed by Harshit Agrawal\n",
    "i = 0 \n",
    "while i< len(str2):\n",
    "    print(i+1, str2[i])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "63b72fdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(16, 21)]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_all_indices(substr, s):\n",
    "    return (m.span() for m in re.finditer(substr, s))\n",
    "\n",
    "list(find_all_indices(\"lover\", \"toym.iasudlov.erlover\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0069c5af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
